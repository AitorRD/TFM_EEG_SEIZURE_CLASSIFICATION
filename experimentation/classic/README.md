# ğŸ§  Sistema Unificado de Experimentos ML & DL
## ClasificaciÃ³n de Convulsiones en EEG

Sistema completo para experimentos de Machine Learning tradicional y Deep Learning con configuraciÃ³n unificada en YAML.

---

## ğŸ“ Estructura de Archivos

```
experimentation/classic/
â”œâ”€â”€ config.yaml           # â­ ÃšNICO archivo de configuraciÃ³n (ML + DL)
â”œâ”€â”€ ml_experiments.py     # â­ Script principal (maneja ML y DL)
â”œâ”€â”€ dl_models.py          # Arquitecturas de Deep Learning (Transformer, CNN, LSTM, GRU)
â””â”€â”€ README.md            # Este archivo
```

---

## ğŸš€ Uso RÃ¡pido

### **OpciÃ³n 1: Machine Learning Tradicional**

```bash
# 1. Editar config.yaml:
#    - experiment.type = "ml"
#    - models.lr.enabled = true (o rf, svc, xgb...)
#    - deep_learning.enabled = false

# 2. Ejecutar:
python experimentation/classic/ml_experiments.py
```

### **OpciÃ³n 2: Deep Learning**

```bash
# 1. Editar config.yaml:
#    - experiment.type = "dl"
#    - deep_learning.enabled = true
#    - dl_models.transformer.enabled = true (o cnn, lstm, gru...)
#    - models.*.enabled = false (deshabilitar ML)

# 2. Ejecutar:
python experimentation/classic/ml_experiments.py
```

---

## âš™ï¸ ConfiguraciÃ³n Detallada

### **config.yaml - ParÃ¡metros Principales**

#### 1ï¸âƒ£ **Tipo de Experimento**
```yaml
experiment:
  type: "ml"  # Cambiar a "dl" para Deep Learning
```

#### 2ï¸âƒ£ **Machine Learning - Activar Modelos**
```yaml
models:
  lr:
    enabled: true  # Logistic Regression
  rf:
    enabled: true  # Random Forest
  svc:
    enabled: true  # SVM
  xgb:
    enabled: true  # XGBoost
  knn:
    enabled: false # K-Nearest Neighbors
```

#### 3ï¸âƒ£ **Deep Learning - Activar Modelos**
```yaml
deep_learning:
  enabled: true
  epochs: 50
  batch_size: 32
  data_format: "raw"  # "raw" o "features"

dl_models:
  transformer:
    enabled: true   # â­ Transformer para secuencias largas
  cnn:
    enabled: false  # CNN para features
  lstm:
    enabled: false  # LSTM para secuencias
  gru:
    enabled: false  # GRU (mÃ¡s rÃ¡pido que LSTM)
```

#### 4ï¸âƒ£ **OptimizaciÃ³n con Optuna**
```yaml
optuna:
  enabled: true
  n_trials: 100  # Reducir a 30-50 para DL
```

#### 5ï¸âƒ£ **ValidaciÃ³n Cruzada**
```yaml
cross_validation:
  enabled: true  # Recomendado para ML, lento para DL
  n_folds: 5
```

#### 6ï¸âƒ£ **Explicabilidad (XAI)**
```yaml
xai:
  enabled: true  # Solo para ML, muy lento para DL
  methods:
    shap:
      enabled: true
    lime:
      enabled: true
```

---

## ğŸ“Š Ejemplos de ConfiguraciÃ³n

### **Ejemplo 1: Comparar varios modelos ML sin optimizaciÃ³n**

```yaml
experiment:
  type: "ml"

models:
  lr:
    enabled: true
  rf:
    enabled: true
  svc:
    enabled: true
  xgb:
    enabled: true

optuna:
  enabled: false  # Sin optimizaciÃ³n, usar parÃ¡metros por defecto

cross_validation:
  enabled: true
  n_folds: 5

xai:
  enabled: true
```

### **Ejemplo 2: Optimizar Random Forest con Optuna**

```yaml
experiment:
  type: "ml"

models:
  rf:
    enabled: true  # Solo Random Forest
  lr:
    enabled: false
  svc:
    enabled: false
  xgb:
    enabled: false

optuna:
  enabled: true
  n_trials: 100

cross_validation:
  enabled: true
```

### **Ejemplo 3: Entrenar Transformer con Early Stopping**

```yaml
experiment:
  type: "dl"
  device: "cuda"  # Usar GPU

deep_learning:
  enabled: true
  epochs: 50
  batch_size: 32
  data_format: "raw"
  early_stopping:
    enabled: true
    patience: 10

dl_models:
  transformer:
    enabled: true
  cnn:
    enabled: false
  lstm:
    enabled: false

models:  # Deshabilitar todos los ML
  lr:
    enabled: false
  rf:
    enabled: false
  svc:
    enabled: false
  xgb:
    enabled: false

optuna:
  enabled: false  # Probar sin optimizaciÃ³n primero

cross_validation:
  enabled: false  # Muy lento para DL

xai:
  enabled: false  # SHAP/LIME lentos para redes neuronales
```

### **Ejemplo 4: Optimizar Transformer con Optuna**

```yaml
experiment:
  type: "dl"
  device: "cuda"

deep_learning:
  enabled: true
  epochs: 30  # Menos Ã©pocas para optimizaciÃ³n

dl_models:
  transformer:
    enabled: true

optuna:
  enabled: true
  n_trials: 30  # Menos trials (DL es lento)

cross_validation:
  enabled: false

xai:
  enabled: false
```

---

## ğŸ”§ Requisitos de InstalaciÃ³n

### **Para Machine Learning:**
```bash
pip install pandas numpy scikit-learn xgboost tsfresh
pip install optuna shap lime matplotlib seaborn pyyaml
```

### **Para Deep Learning (adicional):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install skorch
```

---

## ğŸ“ˆ Flujo de Trabajo

```mermaid
graph TD
    A[Editar config.yaml] --> B{experiment.type?}
    B -->|ML| C[Habilitar modelos ML]
    B -->|DL| D[Habilitar modelos DL]
    C --> E[python ml_experiments.py]
    D --> E
    E --> F[ExtracciÃ³n/Carga de Features]
    F --> G[SelecciÃ³n de Features]
    G --> H{Optuna enabled?}
    H -->|SÃ­| I[Optimizar HiperparÃ¡metros]
    H -->|No| J[Usar ParÃ¡metros por Defecto]
    I --> K[Entrenar Modelos]
    J --> K
    K --> L[Evaluar en ValidaciÃ³n]
    L --> M[Evaluar en Test]
    M --> N[Guardar Resultados]
    N --> O{XAI enabled?}
    O -->|SÃ­| P[Generar Explicaciones]
    O -->|No| Q[Fin]
    P --> Q
```

---

## ğŸ“‚ Resultados Generados

DespuÃ©s de ejecutar, se generan:

```
images/results/
â”œâ”€â”€ ml_test_metrics.png              # Tabla de mÃ©tricas
â”œâ”€â”€ optuna_history_*.html            # Historial de optimizaciÃ³n
â”œâ”€â”€ optuna_importance_*.html         # Importancia de hiperparÃ¡metros
â””â”€â”€ optuna_slice_*.html              # AnÃ¡lisis por parÃ¡metro

images/xai/
â”œâ”€â”€ lr_shap.png                      # Importancia SHAP
â”œâ”€â”€ lr_lime.png                      # Importancia LIME
â””â”€â”€ ... (para cada modelo)

data/processed/
â”œâ”€â”€ features_train.csv               # Features extraÃ­das
â”œâ”€â”€ features_val.csv
â”œâ”€â”€ features_test.csv
â”œâ”€â”€ selected_features.csv            # Features seleccionadas
â””â”€â”€ optuna_results/
    â”œâ”€â”€ optuna_results_lr.csv        # Resultados de optimizaciÃ³n
    â””â”€â”€ ...
```

---

## ğŸ¯ Tips y Recomendaciones

### **Machine Learning:**
- âœ… Usar validaciÃ³n cruzada (cross_validation.enabled = true)
- âœ… Activar XAI para interpretabilidad
- âœ… Probar mÃºltiples modelos simultÃ¡neamente
- âš ï¸ Feature extraction puede tardar (usar features cacheadas si existen)

### **Deep Learning:**
- âœ… Usar GPU (experiment.device = "cuda")
- âœ… Activar Early Stopping (ahorra tiempo)
- âœ… Empezar sin optimizaciÃ³n, luego usar Optuna
- âš ï¸ Desactivar cross_validation (muy lento)
- âš ï¸ Desactivar XAI (SHAP/LIME lentos para redes neuronales)
- âš ï¸ Reducir optuna.n_trials a 30-50

### **OptimizaciÃ³n:**
- Empezar con `optuna.enabled = false` para validar configuraciÃ³n
- Luego activar Optuna para buscar mejores hiperparÃ¡metros
- ML: 100 trials es razonable
- DL: 30-50 trials (cada trial tarda mÃ¡s)

---

## ğŸ› Troubleshooting

**Error: "PyTorch/skorch no disponible"**
```bash
pip install torch skorch
```

**Error: "CUDA no disponible"**
- Cambiar en config.yaml: `experiment.device = "cpu"`
- O instalar CUDA Toolkit y PyTorch con soporte CUDA

**Error: "Features no encontradas"**
- Verificar que existan los CSV de ventanas en `data/processed/windowed/`
- Activar `feature_extraction.enabled = true` para extraerlas

**Entrenamiento muy lento en DL:**
- Reducir `deep_learning.epochs`
- Aumentar `deep_learning.batch_size` (si hay memoria suficiente)
- Reducir `optuna.n_trials` si estÃ¡ habilitado
- Desactivar `cross_validation.enabled`

---

## ğŸ“ Soporte

Para preguntas o problemas:
1. Revisar este README
2. Verificar configuraciÃ³n en config.yaml
3. Revisar logs de ejecuciÃ³n para errores especÃ­ficos

---

**Ãšltima actualizaciÃ³n:** Enero 2026  
**Autor:** Aitor RD  
**Proyecto:** TFM - EEG Seizure Classification
