# Sistema Unificado de Experimentos ML/DL

Este sistema permite ejecutar experimentos de **Machine Learning tradicional** y **Deep Learning** de manera unificada, configurados mediante archivos YAML.

## üìÅ Estructura de Archivos

```
experimentation/classic/
‚îú‚îÄ‚îÄ config.yaml              # Configuraci√≥n para ML tradicional
‚îú‚îÄ‚îÄ config_dl.yaml           # Configuraci√≥n para Deep Learning
‚îú‚îÄ‚îÄ ml_experiments.py        # Script unificado ML/DL
‚îú‚îÄ‚îÄ dl_models.py            # Arquitecturas de DL (PyTorch)
‚îú‚îÄ‚îÄ machine_learning.py     # (Deprecated - usar ml_experiments.py)
‚îî‚îÄ‚îÄ ml_with_cv_and_tuning.py # (Deprecated - usar ml_experiments.py)
```

## üöÄ Instalaci√≥n de Dependencias

### Para ML tradicional:
```bash
pip install pandas numpy scikit-learn xgboost optuna tsfresh shap lime matplotlib seaborn pyyaml
```

### Para Deep Learning (adicional):
```bash
pip install torch torchvision skorch
```

## üìù Uso

### 1. Experimentos de Machine Learning Tradicional

**Configuraci√≥n:** Edita `config.yaml`

```yaml
experiment:
  type: "ml"  # Tipo de experimento

# Activar/desactivar modelos
models:
  lr:
    enabled: true  # Logistic Regression
  rf:
    enabled: true  # Random Forest
  xgb:
    enabled: true  # XGBoost
  svc:
    enabled: false # SVC (desactivado)
  knn:
    enabled: false # KNN (desactivado)

# Configuraci√≥n de Optuna
optuna:
  enabled: true  # Activar optimizaci√≥n
  n_trials: 100

# Validaci√≥n cruzada
cross_validation:
  enabled: true
  n_folds: 5
```

**Ejecutar:**
```bash
python experimentation/classic/ml_experiments.py
```

### 2. Experimentos de Deep Learning

**Configuraci√≥n:** Edita `config_dl.yaml` o cambia `config.yaml`

```yaml
experiment:
  type: "dl"  # Tipo de experimento
  device: "cuda"  # o "cpu"

deep_learning:
  enabled: true
  epochs: 50
  batch_size: 32
  data_format: "raw"  # 'raw' para Transformer/LSTM, 'features' para CNN

# Activar modelo DL
dl_models:
  transformer:
    enabled: true
  lstm:
    enabled: false
  cnn:
    enabled: false
```

**Ejecutar:**
```bash
# Opci√≥n 1: Usar config_dl.yaml
python experimentation/classic/ml_experiments.py

# Modificar para usar otro config
# En ml_experiments.py, cambiar main():
# experiment = MLExperiment(config_path="experimentation/classic/config_dl.yaml")
```

## üéØ Caracter√≠sticas Principales

### Machine Learning
- ‚úÖ **Modelos soportados:** LR, RF, SVC, KNN, XGBoost
- ‚úÖ **Extracci√≥n de features:** TSFRESH autom√°tica
- ‚úÖ **Selecci√≥n de features:** SelectKBest configurable
- ‚úÖ **Validaci√≥n cruzada:** K-Fold estratificada
- ‚úÖ **Optimizaci√≥n:** Optuna con espacios de b√∫squeda personalizables
- ‚úÖ **XAI:** SHAP y LIME para explicabilidad
- ‚úÖ **Class weighting:** Autom√°tico para datos desbalanceados

### Deep Learning
- ‚úÖ **Modelos soportados:** Transformer, LSTM, GRU, CNN 1D
- ‚úÖ **Framework:** PyTorch con skorch (compatible con sklearn)
- ‚úÖ **Early Stopping:** Detiene entrenamiento autom√°tico
- ‚úÖ **LR Scheduling:** Reduce learning rate cuando plateaus
- ‚úÖ **Optimizaci√≥n:** Optuna con hiperpar√°metros de DL
- ‚úÖ **Datos raw:** Trabaja directamente con ventanas temporales
- ‚úÖ **Class weighting:** Autom√°tico en loss function

## üìä Configuraci√≥n Detallada

### Espacios de B√∫squeda Optuna

**Para ML:**
```yaml
models:
  rf:
    optuna_search_space:
      n_estimators:
        type: "int"
        low: 50
        high: 300
      max_depth:
        type: "int"
        low: 10
        high: 50
```

**Para DL:**
```yaml
dl_models:
  transformer:
    optuna_search_space:
      lr:
        type: "loguniform"
        low: 0.00001
        high: 0.001
      d_model:
        type: "categorical"
        choices: [32, 64, 128]
```

### Early Stopping (DL)

```yaml
deep_learning:
  early_stopping:
    enabled: true
    patience: 10        # √âpocas sin mejora
    min_delta: 0.001    # Mejora m√≠nima requerida
    monitor: "val_f1"   # M√©trica a monitorear
```

### Learning Rate Scheduler (DL)

```yaml
deep_learning:
  lr_scheduler:
    enabled: true
    type: "ReduceLROnPlateau"
    factor: 0.5      # LR se multiplica por 0.5
    patience: 5      # √âpocas antes de reducir
    mode: "max"      # max para f1, min para loss
```

## üîß Modificar Arquitecturas DL

Edita `dl_models.py` para personalizar arquitecturas:

```python
class EEGTransformer(nn.Module):
    def __init__(self, input_dim=19, d_model=64, ...):
        super().__init__()
        # Tu arquitectura personalizada aqu√≠
```

## üìà Resultados

Los experimentos generan autom√°ticamente:

- **M√©tricas:** Tabla comparativa en `images/results/`
- **Optuna:** CSV con trials y visualizaciones HTML
- **XAI (ML):** Gr√°ficos SHAP y LIME en `images/xai/`
- **Features:** Features seleccionadas en `data/processed/`

## üí° Ejemplos de Uso

### Comparar todos los modelos ML
```yaml
# config.yaml
experiment:
  type: "ml"

models:
  lr: {enabled: true}
  rf: {enabled: true}
  svc: {enabled: true}
  knn: {enabled: true}
  xgb: {enabled: true}

optuna:
  enabled: false  # Usar par√°metros por defecto
```

### Optimizar solo Random Forest
```yaml
models:
  rf: {enabled: true}
  lr: {enabled: false}
  # ... resto desactivado

optuna:
  enabled: true
  n_trials: 100
```

### Entrenar Transformer con optimizaci√≥n
```yaml
# config_dl.yaml
experiment:
  type: "dl"

deep_learning:
  enabled: true
  epochs: 50

dl_models:
  transformer: {enabled: true}

optuna:
  enabled: true
  n_trials: 30  # DL es m√°s lento
```

### Usar CNN sobre features TSFRESH
```yaml
deep_learning:
  enabled: true
  data_format: "features"  # No 'raw'

dl_models:
  cnn: {enabled: true}

feature_extraction:
  enabled: true  # Extraer features primero

feature_selection:
  enabled: true
  k: 50
```

## üêõ Troubleshooting

### Error: "PyTorch/skorch no disponible"
```bash
pip install torch skorch
```

### Error: "CUDA out of memory"
```yaml
# Reducir batch_size
deep_learning:
  batch_size: 16  # o 8
```

O usar CPU:
```yaml
experiment:
  device: "cpu"
```

### Error: "No se encontraron ventanas con longitud 3000"
Verifica que tus datos tengan ventanas del tama√±o correcto:
```python
df.groupby("window_id").size().value_counts()
```

### Optuna muy lento para DL
Reduce n_trials:
```yaml
optuna:
  n_trials: 10  # En lugar de 100
```

## üéì Mejores Pr√°cticas

1. **Prueba primero sin Optuna:** Usa par√°metros por defecto para verificar que todo funciona
2. **ML antes que DL:** Los modelos ML son m√°s r√°pidos para iterar
3. **Validaci√≥n cruzada en ML, no en DL:** CV es muy costoso computacionalmente para DL
4. **Early Stopping siempre activo:** Evita overfitting en DL
5. **Guarda checkpoints:** Para experimentos largos de DL

## üìö Recursos

- **Optuna:** https://optuna.org/
- **skorch:** https://skorch.readthedocs.io/
- **TSFRESH:** https://tsfresh.readthedocs.io/
- **SHAP:** https://shap.readthedocs.io/

## ü§ù Contribuir

Para agregar un nuevo modelo:

1. **ML:** Agrega el modelo en `create_default_pipeline()` y en `create_optuna_objective()`
2. **DL:** Crea la arquitectura en `dl_models.py` y agr√©gala en `create_dl_model()`
3. **Config:** Agrega la configuraci√≥n en `config.yaml` o `config_dl.yaml`

---

**Autor:** Sistema unificado de experimentos ML/DL  
**Fecha:** 2026  
**Versi√≥n:** 1.0
